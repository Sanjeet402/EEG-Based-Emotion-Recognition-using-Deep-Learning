{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e1ac1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "\n",
    "# === Device Setup ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Load SEED EEG Features ===\n",
    "DATA_PATH = \"D:/SEED_IV/SEED_IV/eeg_feature_smooth\"\n",
    "\n",
    "def pad_or_truncate(features, target_length):\n",
    "    current_length = len(features)\n",
    "    if current_length < target_length:\n",
    "        return np.pad(features, (0, target_length - current_length), mode='constant')\n",
    "    else:\n",
    "        return features[:target_length]\n",
    "\n",
    "def load_eeg_features(sessions=[\"1\", \"2\", \"3\"], feature_type=\"de_movingAve\", num_channels=62):\n",
    "    data = []\n",
    "    labels = []\n",
    "    max_length = 0\n",
    "\n",
    "    for session in sessions:\n",
    "        session_path = os.path.join(DATA_PATH, session)\n",
    "        if not os.path.exists(session_path):\n",
    "            continue\n",
    "\n",
    "        for file in os.listdir(session_path):\n",
    "            if not file.endswith(\".mat\"):\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(session_path, file)\n",
    "            mat = scipy.io.loadmat(file_path)\n",
    "\n",
    "            for trial in range(1, 25):\n",
    "                key = f\"{feature_type}{trial}\"\n",
    "                if key not in mat:\n",
    "                    continue\n",
    "\n",
    "                feature_matrix = mat[key]\n",
    "                if feature_matrix.shape[0] != num_channels:\n",
    "                    continue\n",
    "\n",
    "                trial_features = feature_matrix.reshape(-1)\n",
    "                max_length = max(max_length, len(trial_features))\n",
    "                data.append(trial_features)\n",
    "                labels.append((trial - 1) % 3)\n",
    "\n",
    "    if not data:\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    data_fixed = np.array([pad_or_truncate(x, max_length) for x in data])\n",
    "    return np.array(data_fixed), np.array(labels)\n",
    "\n",
    "# === Load & Normalize Data ===\n",
    "X_fixed, y = load_eeg_features()\n",
    "scaler = StandardScaler()\n",
    "X_fixed = scaler.fit_transform(X_fixed)\n",
    "\n",
    "X_tensor = torch.tensor(X_fixed, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# === Train-Test Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d10c9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 53.6716\n",
      "Epoch [2/50], Loss: 47.3210\n",
      "Epoch [3/50], Loss: 43.9547\n",
      "Epoch [4/50], Loss: 40.7553\n",
      "Epoch [5/50], Loss: 38.3769\n",
      "Epoch [6/50], Loss: 35.3811\n",
      "Epoch [7/50], Loss: 33.7105\n",
      "Epoch [8/50], Loss: 31.3850\n",
      "Epoch [9/50], Loss: 30.4630\n",
      "Epoch [10/50], Loss: 28.6442\n",
      "Epoch [11/50], Loss: 27.7361\n",
      "Epoch [12/50], Loss: 25.9716\n",
      "Epoch [13/50], Loss: 25.4036\n",
      "Epoch [14/50], Loss: 24.3777\n",
      "Epoch [15/50], Loss: 23.7611\n",
      "Epoch [16/50], Loss: 23.2216\n",
      "Epoch [17/50], Loss: 22.5027\n",
      "Epoch [18/50], Loss: 21.1208\n",
      "Epoch [19/50], Loss: 20.3296\n",
      "Epoch [20/50], Loss: 20.2525\n",
      "Epoch [21/50], Loss: 19.6542\n",
      "Epoch [22/50], Loss: 19.0874\n",
      "Epoch [23/50], Loss: 18.3753\n",
      "Epoch [24/50], Loss: 18.5413\n",
      "Epoch [25/50], Loss: 18.1042\n",
      "Epoch [26/50], Loss: 17.8361\n",
      "Epoch [27/50], Loss: 17.1664\n",
      "Epoch [28/50], Loss: 17.8592\n",
      "Epoch [29/50], Loss: 16.8994\n",
      "Epoch [30/50], Loss: 16.4595\n",
      "Epoch [31/50], Loss: 16.1298\n",
      "Epoch [32/50], Loss: 16.4212\n",
      "Epoch [33/50], Loss: 15.1837\n",
      "Epoch [34/50], Loss: 15.5273\n",
      "Epoch [35/50], Loss: 15.2110\n",
      "Epoch [36/50], Loss: 15.1837\n",
      "Epoch [37/50], Loss: 14.3470\n",
      "Epoch [38/50], Loss: 14.2379\n",
      "Epoch [39/50], Loss: 14.4221\n",
      "Epoch [40/50], Loss: 14.3305\n",
      "Epoch [41/50], Loss: 13.4705\n",
      "Epoch [42/50], Loss: 13.4997\n",
      "Epoch [43/50], Loss: 13.0159\n",
      "Epoch [44/50], Loss: 13.3849\n",
      "Epoch [45/50], Loss: 12.8805\n",
      "Epoch [46/50], Loss: 12.6960\n",
      "Epoch [47/50], Loss: 13.0848\n",
      "Epoch [48/50], Loss: 12.6956\n",
      "Epoch [49/50], Loss: 12.6218\n",
      "Epoch [50/50], Loss: 12.7537\n",
      "âœ… EEGNet-Optimized Training Complete!\n",
      "\n",
      "Accuracy: 0.8889\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9333    0.8861    0.9091        79\n",
      "           1     0.9014    0.9014    0.9014        71\n",
      "           2     0.8286    0.8788    0.8529        66\n",
      "\n",
      "    accuracy                         0.8889       216\n",
      "   macro avg     0.8878    0.8888    0.8878       216\n",
      "weighted avg     0.8908    0.8889    0.8894       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Device config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class EEGNetOptimized(nn.Module):\n",
    "    def __init__(self, num_classes=3, input_channels=62, input_samples=320):\n",
    "        super(EEGNetOptimized, self).__init__()\n",
    "\n",
    "        self.temporal_conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=(1, 64), padding=(0, 32), bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "\n",
    "        self.depthwise_conv = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=(input_channels, 1), groups=16, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "\n",
    "        self.separable_conv = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=(1, 16), padding=(0, 8), bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "\n",
    "        # Drop the classifier here; we'll create it dynamically in forward\n",
    "        self.fc1 = nn.Linear(1, 1)  # dummy init, will reset later\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # [batch, 1, channels, samples]\n",
    "        x = self.temporal_conv(x)\n",
    "        x = self.depthwise_conv(x)\n",
    "        x = self.separable_conv(x)\n",
    "\n",
    "        x = x.flatten(start_dim=1)  # flatten everything but batch dimension\n",
    "        if isinstance(self.fc1, nn.Linear) and self.fc1.in_features != x.shape[1]:\n",
    "            self.fc1 = nn.Sequential(\n",
    "                nn.Linear(x.shape[1], 128),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(128, self.num_classes)\n",
    "            ).to(x.device)\n",
    "\n",
    "        out = self.fc1(x)\n",
    "        return out\n",
    "\n",
    "# Initialize model\n",
    "model = EEGNetOptimized(num_classes=3, input_channels=62, input_samples=320).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        batch_X = batch_X.view(-1, 62, 320)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}')\n",
    "\n",
    "print(\"âœ… EEGNet-Optimized Training Complete!\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "all_preds, all_targets = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        batch_X = batch_X.view(-1, 62, 320)\n",
    "\n",
    "        outputs = model(batch_X)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(batch_y.cpu().numpy())\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(all_targets, all_preds)\n",
    "report = classification_report(all_targets, all_preds, digits=4)\n",
    "print(f\"\\nAccuracy: {acc:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba481b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§  Region-wise Accuracy:\n",
      "Frontal: 0.5972\n",
      "Temporal: 0.5648\n",
      "Parietal: 0.5694\n",
      "Occipital: 0.4398\n",
      "Central: 0.3796\n"
     ]
    }
   ],
   "source": [
    "def region_wise_analysis(model, X_tensor, y_tensor, region_channels_dict, total_channels=62, input_samples=320):\n",
    "    model.eval()\n",
    "    results = {}\n",
    "\n",
    "    for region, channels in region_channels_dict.items():\n",
    "        # Create region-specific inputs\n",
    "        X_region = X_tensor[:, channels, :]\n",
    "\n",
    "        # Pad to original 62 channels (with zeros for unused channels)\n",
    "        padded = torch.zeros((X_region.shape[0], total_channels, input_samples))\n",
    "        padded[:, channels, :] = X_region  # Fill only region's channels\n",
    "\n",
    "        # Split into test set (same 80/20 split)\n",
    "        X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "            padded, y_tensor, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        X_test_reg = X_test_reg.to(device)\n",
    "        y_test_reg = y_test_reg.to(device)\n",
    "\n",
    "        # Run model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(X_test_reg)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            acc = accuracy_score(y_test_reg.cpu().numpy(), preds.cpu().numpy())\n",
    "\n",
    "        results[region] = acc\n",
    "\n",
    "    return results\n",
    "\n",
    "# === Define Brain Regions by Channel Indices ===\n",
    "region_channels = {\n",
    "    'Frontal': list(range(0, 20)),      # Example indices, adjust as per EEG cap layout\n",
    "    'Temporal': list(range(20, 30)),\n",
    "    'Parietal': list(range(30, 45)),\n",
    "    'Occipital': list(range(45, 52)),\n",
    "    'Central': list(range(52, 62))\n",
    "}\n",
    "\n",
    "# === Run Region-Wise Analysis ===\n",
    "region_scores = region_wise_analysis(model, X_tensor.view(-1, 62, 320), y_tensor, region_channels)\n",
    "\n",
    "# === Display Results ===\n",
    "print(\"\\nðŸ§  Region-wise Accuracy:\")\n",
    "for region, score in region_scores.items():\n",
    "    print(f\"{region}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2296b66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "EEGNetOptimized                          [16, 3]                   --\n",
       "â”œâ”€Sequential: 1-1                        [16, 16, 62, 321]         --\n",
       "â”‚    â””â”€Conv2d: 2-1                       [16, 16, 62, 321]         1,024\n",
       "â”‚    â””â”€BatchNorm2d: 2-2                  [16, 16, 62, 321]         32\n",
       "â”‚    â””â”€ELU: 2-3                          [16, 16, 62, 321]         --\n",
       "â”‚    â””â”€Dropout: 2-4                      [16, 16, 62, 321]         --\n",
       "â”œâ”€Sequential: 1-2                        [16, 32, 1, 321]          --\n",
       "â”‚    â””â”€Conv2d: 2-5                       [16, 32, 1, 321]          1,984\n",
       "â”‚    â””â”€BatchNorm2d: 2-6                  [16, 32, 1, 321]          64\n",
       "â”‚    â””â”€ELU: 2-7                          [16, 32, 1, 321]          --\n",
       "â”‚    â””â”€Dropout: 2-8                      [16, 32, 1, 321]          --\n",
       "â”œâ”€Sequential: 1-3                        [16, 64, 1, 322]          --\n",
       "â”‚    â””â”€Conv2d: 2-9                       [16, 64, 1, 322]          32,768\n",
       "â”‚    â””â”€BatchNorm2d: 2-10                 [16, 64, 1, 322]          128\n",
       "â”‚    â””â”€ELU: 2-11                         [16, 64, 1, 322]          --\n",
       "â”‚    â””â”€Dropout: 2-12                     [16, 64, 1, 322]          --\n",
       "â”œâ”€Sequential: 1-4                        [16, 3]                   --\n",
       "â”‚    â””â”€Linear: 2-13                      [16, 128]                 2,637,952\n",
       "â”‚    â””â”€ELU: 2-14                         [16, 128]                 --\n",
       "â”‚    â””â”€Dropout: 2-15                     [16, 128]                 --\n",
       "â”‚    â””â”€Linear: 2-16                      [16, 3]                   387\n",
       "==========================================================================================\n",
       "Total params: 2,674,339\n",
       "Trainable params: 2,674,339\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 547.30\n",
       "==========================================================================================\n",
       "Input size (MB): 1.27\n",
       "Forward/backward pass size (MB): 89.44\n",
       "Params size (MB): 10.70\n",
       "Estimated Total Size (MB): 101.41\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size=(16, 62, 320))  # 16 is a dummy batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f80e9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
